# -*- coding: utf-8 -*-
"""streamlit_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bkX1y1XGm9CZKmTiN2OwU061Y2b_1y1a
"""

##############################
# STREAMLIT APP - Dyslexia + Handwriting Feature Screening
# Full Multi-Page Version
##############################

import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
import cv2, io, json, pickle, csv, os
import matplotlib.pyplot as plt

###############################################
# ------------  CONFIG & PATHS --------------
###############################################

DYSLEXIA_MODEL_PATH = "/content/drive/MyDrive/Hybrid_BiLSTM_model/mobilenetv2_bilstm_best_thr_044.h5"
THRESHOLD_PATH      = "/content/drive/MyDrive/Hybrid_BiLSTM_model/best_threshold.json"
DYSLEXIA_CLASS_MAP  = "/content/drive/MyDrive/Hybrid_BiLSTM_model/class_indices_best.pkl"

FEATURE_MODEL_PATH  = "/content/drive/MyDrive/DL-3 Model_TUNED_version/BEST_TUNED_MODEL.keras"
FEATURE_CLASS_MAP   = "/content/drive/MyDrive/DL-3 Model/class_indices.pkl"

RESULTS_CSV = "screening_history.csv"
IMG_SIZE = (160,160)

###############################################
# ------------ MODEL LOADING ------------------
###############################################

@st.cache_resource
def load_all_models():
    dys_model = tf.keras.models.load_model(DYSLEXIA_MODEL_PATH)
    feat_model = tf.keras.models.load_model(FEATURE_MODEL_PATH)

    with open(THRESHOLD_PATH, "r") as f:
        THR = json.load(f)["threshold"]

    with open(DYSLEXIA_CLASS_MAP, "rb") as f:
        m1 = pickle.load(f)
    inv_dys = {v:k for k,v in m1.items()}

    with open(FEATURE_CLASS_MAP, "rb") as f:
        m2 = pickle.load(f)
    inv_feat = {v:k for k,v in m2.items()}

    return dys_model, THR, inv_dys, feat_model, inv_feat


dys_model, BEST_THRESHOLD, inv_map_dys, feat_model, inv_map_feat = load_all_models()


###############################################
# ------------ PREPROCESSING ------------------
###############################################
def preprocess(img):
    img = img.convert("RGB").resize(IMG_SIZE)
    arr = np.array(img)/255.0
    arr = np.expand_dims(arr,0)
    return arr


###############################################
# ------------ OCR-LIKE ERROR DETECTION -------
###############################################
def detect_reversal_like_errors(pil_img):
    """
    Lightweight OCR-free reversal detection using contour-level shape features.
    """
    img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2GRAY)
    img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,
                                cv2.THRESH_BINARY_INV,11,10)

    contours,_ = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)

    reversal_flags = []
    inversion_flags = []
    suspicious_letters = []

    for cnt in contours:
        x,y,w,h = cv2.boundingRect(cnt)
        roi = img[y:y+h, x:x+w]

        if w*h < 120:   # tiny noise
            continue

        # Aspect-based reversal detection
        ratio = w / (h+1)

        # detect p/q or b/d-like flips
        if ratio > 0.9:
            reversal_flags.append(True)
            suspicious_letters.append("Possible (b/d or p/q)")
        else:
            reversal_flags.append(False)

        # detect upside-down shapes
        vert_sym = np.sum(np.abs(roi - cv2.flip(roi,0)))
        horiz_sym = np.sum(np.abs(roi - cv2.flip(roi,1)))

        if vert_sym < horiz_sym * 0.6:
            inversion_flags.append(True)
            suspicious_letters.append("Possible inversion (upside-down)")
        else:
            inversion_flags.append(False)

    return {
        "reversal_detected": any(reversal_flags),
        "inversion_detected": any(inversion_flags),
        "samples": suspicious_letters
    }



###############################################
# ------------ GRAD-CAM ------------------------
###############################################
def make_gradcam_heatmap(img_array, model, last_conv_layer_name="Conv_1"):
    grad_model = tf.keras.models.Model(
        [model.inputs],
        [model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_out, preds = grad_model(img_array)
        pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    grads = tape.gradient(class_channel, conv_out)
    pooled = tf.reduce_mean(grads, axis=(0,1,2))
    conv_out = conv_out[0]

    heatmap = tf.reduce_sum(tf.multiply(pooled, conv_out), axis=-1)
    heatmap = np.maximum(heatmap,0) / np.max(heatmap)
    heatmap = cv2.resize(heatmap, IMG_SIZE)
    return heatmap



###############################################
# ------------ SEVERITY ------------------------
###############################################
def severity_from_score(score_pct):
    if score_pct <= 0:
        return "Normal", 0
    if score_pct <= 30:
        return "Mild", 1
    if score_pct <= 70:
        return "Moderate", 2
    return "Severe", 3


###############################################
# ------------ SAVE HISTORY --------------------
###############################################
def log_result(data):
    file_exists = os.path.isfile(RESULTS_CSV)
    with open(RESULTS_CSV, "a", newline='') as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(data.keys())
        writer.writerow(data.values())


###############################################
# ------------ STREAMLIT MULTIPAGE -------------
###############################################
st.set_page_config(page_title="Dyslexia Screening App", layout="wide")

menu = st.sidebar.radio(
    "üìå Navigation",
    ["Home (Predict)", "Deep Analysis", "History"]
)

###########################################################
# --------------------- HOME PAGE -------------------------
###########################################################
if menu == "Home (Predict)":
    st.title("üìù Dyslexia & Handwriting Feature Screening")

    uploaded = st.file_uploader("Upload handwriting image", type=["jpg","png","jpeg"])
    camera = st.camera_input("Or capture using camera")

    blob = None
    if uploaded:
        blob = uploaded.read()
    elif camera:
        blob = camera.read()

    if blob is not None:
        img = Image.open(io.BytesIO(blob)).convert("RGB")
        st.image(img, caption="Uploaded Image", width=350)

        arr = preprocess(img)

        # 1Ô∏è‚É£ Dyslexia probability
        dys_prob = float(dys_model.predict(arr)[0][0])
        dys_pct = dys_prob * 100
        dys_label = "dyslexic" if dys_prob > BEST_THRESHOLD else "non_dyslexic"
        severity_txt, severity_id = severity_from_score(dys_pct if dys_label=="dyslexic" else 0)

        # 2Ô∏è‚É£ Handwriting features (3-class)
        feat_pred = feat_model.predict(arr)[0]
        feat_idx = np.argmax(feat_pred)
        feat_class = inv_map_feat[feat_idx]
        feat_conf = float(feat_pred[feat_idx])

        # Display
        st.subheader("üìä Prediction Results")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Dyslexia Probability", f"{dys_pct:.2f}%")
            st.write(f"Prediction: **{dys_label}**")
            st.write(f"Severity: **{severity_txt}**")

        with col2:
            st.metric("Handwriting Class", feat_class)
            st.write(f"Confidence: {feat_conf*100:.2f}%")

        # Save every prediction
        log_result({
            "probability": dys_pct,
            "label": dys_label,
            "severity": severity_txt,
            "feature": feat_class,
            "feature_conf": feat_conf
        })

        st.success("Prediction complete! Go to **Deep Analysis** tab for more insights.")

###########################################################
# --------------------- ANALYSIS PAGE ---------------------
###########################################################
elif menu == "Deep Analysis":
    st.title("üî¨ Deep Analysis: Heatmap, OCR & Errors")

    uploaded = st.file_uploader("Upload handwriting again", type=["jpg","png","jpeg"])

    if uploaded:
        img = Image.open(uploaded).convert("RGB")
        arr = preprocess(img)

        # 1Ô∏è‚É£ Grad-CAM Heatmap
        heatmap = make_gradcam_heatmap(arr, dys_model)
        heatmap_color = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)
        superimposed = cv2.addWeighted(cv2.cvtColor(np.array(img.resize(IMG_SIZE)), cv2.COLOR_RGB2BGR),
                                       0.5, heatmap_color, 0.5, 0)

        st.subheader("üî• Grad-CAM Heatmap (Model Attention)")
        st.image(superimposed, channels="BGR", width=450)

        # 2Ô∏è‚É£ OCR-like reversal detection
        st.subheader("üîÅ Reversal / Inversion Detection")
        rev = detect_reversal_like_errors(img)

        if rev["reversal_detected"]:
            st.error("Reversal-like errors detected")
        if rev["inversion_detected"]:
            st.warning("Inversion (upside-down) patterns detected")

        st.write("Detected letter anomalies:")
        st.write(rev["samples"])


###########################################################
# --------------------- HISTORY PAGE -----------------------
###########################################################
elif menu == "History":
    st.title("üìÇ Screening History")

    if os.path.isfile(RESULTS_CSV):
        st.download_button("Download history CSV", open(RESULTS_CSV,"rb").read(), file_name="history.csv")
        with open(RESULTS_CSV,"r") as f:
            st.dataframe(list(csv.reader(f)))
    else:
        st.info("No predictions stored yet.")
